# `classification/uzay`

This is the main folder for classification evaluation and deployment. **NOTE**: For the actual code for training and development, please contact Jiawei Ma from DVMM. An ideal setup would be to put the main code directly under `classification`. Since the contents here are mainly focused on evaluation, we'll be skipping all details related to training. **NOTE**: If the classifier model changes in the future, for whatever reason, code here would need to be adapted to reflect the newest changes in model architecture. The code and descriptions here are what worked for us at some point in the past.

## Contents

* `data/`: Placeholder data folder for storing extracted membrane images of test kits. The membrane images within this folder should be placed in a subfolder with a descriptive name. For example, `btnx-raw-train` for BTNx membranes to be used for training. Most membranes can be found in the GDrive folder called `covid_test`. Please ask Siddarth Arumugam if you don't have access to this GDrive folder.

* `dataloader/`: PyTorch dataloader utilities (e.g. augmentation pool).

* `deployment/`: Files for deployment to cloud. **NOTE**: Before running the code within this sub-folder, make sure to place the `.pt` or `.pth` file of the saved classification model here. The deployment procedure for all types of machine learning models are described in [*Cloud Model Deployment Documentation*](https://docs.google.com/document/d/1EAmBFSLx-ufW4sXXMWB2YcmJvLxy9XkA-dbNRiu1M6M/edit?usp=sharing).
	* `deploy.sh`: This bash script creates a `.mar` file for the classification model, and subsequently starts `torchserve` for local deployment. The `.mar` file will be later deployed to AWS SageMaker. **NOTE**: Make sure to replace `--serialized-file quidelag_classifier.pth` with the desired saved model filepath. Other variables to play around with are `--model-name` for `torch-model-archiver` and `--models` for `torchserve`. Make sure that it follows the following rule: `--models {--model-name}={--model-name}.mar`.
	* `kill.sh`: Kills `torchserve` and deletes the temporary folders `model_store` and `logs`.
	* `classifier_handler.py`: Handles the inference of the deployed model. **NOTE**: Make sure to change the `self.model_filename` to the desired saved model filepath.
	* `classifier_model.py`: Contains the implementation of the model.
	* `test.sh`: Bash script for testing. Feel free to change this to match different tests you want to perform.
	* `kit_data.json`: JSON that contains manufacturer specs for various kits. Make sure this is the most up-to-date version.

* `eval/`: Temporary output folder for evaluation. This folder will be populated with predictions from the classification model.
	* `check_agreement.py`: This script will run comparison analysis between a **labels** file and a **predictions file**, and compute various performance metrics for classification. Please read the code to see the various available outputs (e.g. threshold analysis, etc.). The main variables to set in this script are:
		* `df1`: This is the first data frame for **labels**. Our labels files are usually in Excel format. Make sure to change the path of `pd.read_excel()` to the desired filepath.
		* `df2`: This is the second data frame for **predictions**, and will be automatically generated by `main.py` in CSV format. Make sure to change the path of `pd.read_csv()` to the desired filepath.
		* `OUTPUT_ID`: The final results will be outputted to a separate CSV and a TXT file. The `OUTPUT_ID` is essentially the name of these joint files.
		* `NUM_ZONES`: The number of zones of the test kit we are dealing with (e.g. `3` for BTNx).

* `logs/`: You will store the saved `.pt` or `.pth` files for classifier models under here, in the given format. Explicitly, we have `logs/v6/Quidel_Ag/max_acc.pth`, where `v6` is the version of the currently tested-out classification model, `Quidel_Ag` is the name of the test kit for which the classifier has been developed for, and `max_acc.pth` is the saved classifier model file.

* `models/`: Various models and layers implemented for this task.

* `trainer/`: Scripts related to different training strategies implemented for this task.

* `utils_/`: Contains utilities used for training the classifier model.

* `check_zones.py`: Script for generating and saving cropped out zones from membranes for visual investigation. Please see the three variables and their descriptions inside the script: `--membranes_dir`, `--kit_id`, and `--json_path`.

* `gradcam.py`: Implements GradCAM and GradCAM++ for computing gradient-based class activation maps which will be used for visual investigation and interpretability analysis. 

* `kit_data_v5.json`: JSON that contains manufacturer specs for various kits. Make sure this is the most up-to-date version.

* `utils.py`: Utilities for implementing GradCAM and GradCAM++.

* `main.py`: The main script for running local inference on a given set of membranes. Sample calls are included in the docstring of the script. The `argparse` arguments for this script are as follows:
	* `--model_type`: The type of the model. The current choices are `ResNet18` and `ResNet18ORI`. You can leave this at the default value of `ResNet18ORI`.
	* `--kit_id`: The ID of the test kit; should match key in `kit_data_v5.json` and should match subfolder in `logs/`. Choices are `BTNx`, `ACON_Ab`, `ACON_Ag`, `DeepBlue_Ag`, `RapidConnect_Ab`, `Paramount_Ag`, `Quidel_Ag`, and `AccessBio_Ag`.
	* `--model_version`: The version of the model. The current default version is `v6`. This should match the subfolder in `logs/`.
	* `--json_path`: The path to the JSON that contains manufacturer specs for various kits. Default value is `kit_data_v5.json`.
	* `--membranes_dir`: This is a required argument, and it should be the path to a folder with several membrane images inside `data/`.
	* `--output_name`: The output name is a name of your choice which will be prefixed to output files. For example, the predictions of the model will be saved to `eval/<output_name>.csv`.
	* `--input_is_zones`: Set this flag to True if `--membranes_dir` points to a directory of images that are individual zones, rather than membranes.
	* `--gradcam`: Set this flag to True if you want to perform GradCAM and GradCAM++ on the membranes. **NOTE**: This operation increases the runtime severely.
	* `--white_balance`: Set this flag to True if you want to apply white-balancing to the input membranes before passing them through the model. In our past experiments, we found that this helps with performance (e.g. faint lines, different light conditions, etc.).
	* `--threshold_rejection`: Set this flag to True if you want to apply threshold rejection, i.e. reject individual zones (`-1`) as opposed to classifying them as positive (`1`) or negative (`0`).



